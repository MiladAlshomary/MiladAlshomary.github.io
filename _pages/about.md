---
layout: about
title: About
permalink: /
subtitle: Columbia University. <a href='https://datascience.columbia.edu/'> Data Science Institute </a>

profile:
  align: right
  image: milad_photo.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Schapiro Center</p>
    <p>530 W 120th St</p>
    <p>New York, NY 10027</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

I am a postdoctoral research scientist at the <a href='https://datascience.columbia.edu/'> Data Science Institute </a> at Columbia University, with a background in Natural Language Processing (NLP) focusing on human argumentation and the explainability of machine learning models. My research explores the intersection of argumentation and explainability, driven by the increasing need to understand the behavior of AI systems.

I earned my **PhD in Computer Science from Paderborn University** (July 2018 - December 2023). My doctoral research, resulted in the dissertation titled <a href='https://digital.ub.uni-paderborn.de/hs/content/titleinfo/7498576'>“Audience-Aware Argument Generation,”</a> under the supervision of Professor Henning Wachsmuth, aimed to advance the effectiveness of argument generation by emphasizing the importance of relevance, consideration of the opponent's argument, and addressing the audience's interests. My current **postdoctoral research at Columbia University (January 2024 - Present)**, under the supervision of Professor Kathleen McKeown and Professor Smaranda Muresan, focuses on developing methods for authorship attribution, with a particular emphasis on making these models explainable. This work involves studying how humans explain in dialogues and interpreting latent spaces to understand what aspects of style authorship attribution models capture. Recentely, I joined a project to study how vision LLMs perform a formal analysis of the style of art pieces - a collaboration between computer scientists, science and technology studies (STS) scholars, art historians, and legal scholars.


### Demos

- [LLMs as Science Journalists](https://huggingface.co/spaces/miladalsh/communicating-science-to-the-public)
- [IXAM: Interactive Explainability for Authorship Attribution Models](https://huggingface.co/spaces/miladalsh/interactive-explainability-for-aa-analysis)